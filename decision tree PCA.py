from matplotlib import pyplot as plt
import functions
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

# path dei file
X_filtered_path = "dataset/X_filtered.csv"
Train_Y_path = "dataset/EmberYTrain.csv"
Test_X_path = "dataset/EmberTest/EmberXTest.csv"
Test_Y_path = "dataset/EmberTest/EmberYTest.csv"

# caricamento dei file
X = functions.load(X_filtered_path)
Y = functions.load(Train_Y_path)
Ember_X_Test = functions.load(Test_X_path)
Ember_Y_Test = functions.load(Test_Y_path)

# addestramento dell'oggetto 'pca' sul dataframe fornito in input
pca, pca_list, explained_variance = functions.pca(X)

# Applicazione pca con metodo 'transform'
XPCA = functions.apply_pca(X, pca, pca_list)

# settaggio del numero di fold da effettuare tramite il K-Fold Stratificato
folds = 5

# esecuzione del K-fold Stratificato su XPCA
ListXTrainPCA, ListXTestPCA, ListYTrainPCA, ListYTestPCA = functions.stratified_k_fold(XPCA, Y, folds)

# inizializzazione della soglia minima e della soglia massima e dello step con cui muoversi tra le due soglie
minThreshold = 0.95
stepThreshold = 0.01
maxThreshold = 1.0

# esecuzione della ricerca dei migliori parametri per l'albero
best_criterion_PCA, best_TH, best_N_PCA, best_Eval = functions.determine_decision_tree_k_fold_configuration_PCA(ListXTrainPCA, ListYTrainPCA, ListXTestPCA, ListYTestPCA, explained_variance, minThreshold, maxThreshold, stepThreshold)
print("\n\nMIGLIORI PARAMETRI DELL'ALBERO (PCA) INDIVIDUATI:\nFeature Ranking tramite explained variance:\n", 'Criterio: ', best_criterion_PCA, ', soglia explained variance: ', best_TH, ', N: ', best_N_PCA, ', CV F', best_Eval, '\n')


# addestramento di un albero decisionale con le migliori feature selezionate e il miglior criterio individuato
DTPCA = functions.decision_tree_learner(XPCA.iloc[:, :best_N_PCA], Y, best_criterion_PCA)

# filtraggio di EmberXTest.csv in base alle feature utilizzate durante il fit dell'oggetto 'pca' (feature di X_filtered)
Ember_X_Test_filtrato = Ember_X_Test[X.columns]

# utilizzo dell'oggetto 'pca' su Ember_X_Test_filtrato
Ember_X_Test_PCA = functions.apply_pca(Ember_X_Test_filtrato, pca, pca_list)

# selezione delle n feature individuate
Ember_X_Test_DTPCA = Ember_X_Test_PCA.iloc[:, 0:best_N_PCA]

# selezione dei nomi delle colonne di XPCA (pc1, pc2, ..., pcn)
feature_names = XPCA.iloc[:, :best_N_PCA].columns.values

# visualizza la struttura dell'albero DTPCA
functions.show_tree(DTPCA, feature_names)

# previsioni dell'albero sul dataset di test
y_predicted_DTPCA = DTPCA.predict(Ember_X_Test_DTPCA)

# calcolo della matrice di confusione di DTPCA
conf_matrix_DTPCA = confusion_matrix(Ember_Y_Test, y_predicted_DTPCA)

# settaggio parametri per la visualizzazione della matrice di confusione di DTPCA
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_DTPCA)
disp.plot(cmap='Blues')
disp.ax_.set_title('Matrice di confusione di DTPCA')

# visualizzazione della matrice di confusione di DTPCA
plt.show()

# stampa del report di classificazione di DTPCA
class_report_DTPCA = classification_report(Ember_Y_Test, y_predicted_DTPCA)
print("\nReport di classificazione di DTPCA:\n")
print(class_report_DTPCA, "\n")
