import math
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.feature_selection import mutual_info_classif
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import plot_tree
from sklearn.metrics import f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier


def pre_elaboration_data(X):
    X_described = X.describe()
    return X_described


def load(a):
    dataset = pd.read_csv(a)
    return dataset


def pre_boxplot_analysis_data(X, Y):
    print("\nEffettuando il boxplotting...\n")

    # unione di X e Y
    merged_df = pd.merge(X, Y, left_index=True, right_index=True)

    # numero di boxplot per pagina
    plots_per_page = 20

    # calcolo del numero totale di boxplot
    num_plots = len(X.columns)

    # calcolo del numero di pagine necessarie
    num_pages = math.ceil(num_plots / plots_per_page)

    # creazione dei boxplot per pagina
    for page in range(num_pages):
        start_plot = page * plots_per_page
        end_plot = min((page + 1) * plots_per_page, num_plots)

        fig, axes = plt.subplots(nrows=math.ceil((end_plot - start_plot) / 5), ncols=5, figsize=(20, 10))

        for i, col in enumerate(X.columns[start_plot:end_plot]):
            row_index = i // 5
            col_index = i % 5
            ax = axes[row_index, col_index]
            merged_df.boxplot(column=col, by='Label', ax=ax)
            ax.set_title(col)

            # dimensioni del testo per le etichette degli assi
            ax.xaxis.label.set_size(8)
            ax.yaxis.label.set_size(8)

        plt.tight_layout()

    # stampa del boxplot
    plt.show()


def mutual_info_rank(X, Y):
    print("\nCalcolando il Mutual Information rank...")

    # creazione di una lista contenente i nomi degli attributi di X
    independent_list = list(X.columns.values)

    # riproducibilità
    seed = 42
    np.random.seed(seed)

    # creazione di un dizionario avente come chiavi gli attributi di X e come valori le mutue informazioni
    res = dict(zip(independent_list, mutual_info_classif(X, np.ravel(Y), discrete_features=False, random_state=seed)))

    # ordinamento dei valori del dizionario "res" in ordine decrescente di rank
    sorted_x = sorted(res.items(), key=lambda kv: kv[1], reverse=True)

    print("\nCalcolando il Mutual Information rank... completato\n")

    # restituzione dizionario ordinato in decrescenza
    return sorted_x


def top_feature_select(rank, threshold):
    print("\nSelezionando le migliori feature...")

    # filtraggio degli elementi di "rank". Condizione: valore >= threshold
    filtered_sorted_x = [(k, v) for k, v in rank if v >= threshold]

    print("\nSelezionando le migliori feature... completato!\n")

    # restituzione del filtraggio sugli elementi di "rank"
    return filtered_sorted_x


def pca(x):
    print("\nEffettuando la PCA sul dataframe fornito...\n")

    # inizializzazione dell'oggetto PCA.
    # parametro: numero di colonne di X
    pca = PCA(n_components=len(x.columns.values))

    # esecuzione metodo 'fit' su X
    pca.fit(x)

    # creazione lista contenente le componenti principali rinominate in "pc1, pc2, ..., pcn"
    pc_list = [f'pc{i + 1}' for i in range(pca.n_components_)]

    # acquisizione della explained variance
    explained_variances = pca.explained_variance_ratio_
    print("\nExplained variances:\n", explained_variances)
    print("\nSomma delle explained variances:\n", sum(explained_variances))

    print("\nEffettuando la PCA sul dataframe fornito... completato!\n")

    return pca, pc_list, explained_variances


def apply_pca(X, pca, pc_list):
    print("\nApplicando la PCA con metodo 'transform'...")

    # esecuzione metodo 'transorm' su X
    transformed_data = pca.transform(X)

    # creazione di un DataFrame per memorizzare le componenti principali
    # parametri input: dati di X trasformati e nomi delle colonne (pc1, ..., pcn)
    pc_df = pd.DataFrame(transformed_data, columns=pc_list)

    print("\nApplicando la PCA con metodo 'transform'... completato!\n")

    # restituzione del DataFrame
    return pc_df


def number_of_top_pc_select(explained_variances, threshold):

    # se la soglia è 1, restituzione del numero totale di componenti principali
    if threshold == 1:
        return len(explained_variances)

    # calcolo della somma cumulativa delle explained variance
    cumsum_variances = np.cumsum(explained_variances)

    # identificazione del numero minimo di "pc" la cui varianza supera la threshold
    num_components = np.argmax(cumsum_variances >= threshold) + 1

    # restituzione del numero delle "pc" selezionate
    return num_components


def stratified_k_fold(X, Y, folds):
    print("\n\nEsecuzione del K-fold Stratificato...")

    # riproducibilità
    seed = 42
    np.random.seed(seed)

    # inizializzazione del K-Fold Stratificato
    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)

    # dichiarazione delle liste che memorizzeranno successivamente i dati di ciascun fold
    List_X_Train, List_X_Test, List_Y_Train, List_Y_Test = [], [], [], []

    # iterazione sui fold generati dal K-Fold Stratificato
    for train_index, test_index in skf.split(X, Y):

        # divisione del dataset in training set e test set sulla base degli indici selezionati per ogni fold
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]

        # accodamento del training set e del test set nelle liste corrispondenti, sia per X che per Y
        List_X_Train.append(X_train)
        List_X_Test.append(X_test)
        List_Y_Train.append(Y_train)
        List_Y_Test.append(Y_test)

    print("\nEsecuzione del K-fold Stratificato... completata!\n")

    return List_X_Train, List_X_Test, List_Y_Train, List_Y_Test


def decision_tree_learner(X, y, c):

    # creazione di un albero decisionale con il criterio specificato
    tree = DecisionTreeClassifier(criterion=c, min_samples_split=500, random_state=42)

    # addestramento dell'albero decisionale sul training set
    tree.fit(X, y)

    # ottenimento delle informazioni sul numero dei nodi e delle foglie dell'albero
    num_nodes = tree.tree_.node_count
    num_leaves = tree.get_n_leaves()

    # stampa delle informazioni ottenute
    print(f"\nNumber of nodes in the learned tree: {num_nodes}")
    print(f"\nNumber of leaves in the learned tree: {num_leaves}\n")

    # restituzione dell'albero decisionale
    return tree


def show_tree(T, feature_names):

    # visualizzazione dell'albero decisionale "T"
    plt.figure(figsize=(12, 15))
    plot_tree(T, filled=True, feature_names=feature_names, fontsize=3)
    plt.show()


def determine_decision_tree_k_fold_configuration(X_Train, Y_Train, X_Test, Y_Test, rank, min_threshold, max_threshold, step_threshold):
    sum_f1_scores = 0
    best_f1 = 0
    best_config = None
    best_threshold = 0
    selected_features_lenght = 0

    print("\n\nDeterminando la configurazione migliore dell'albero...")

    for criterion in ['gini', 'entropy']:
        for threshold in np.arange(min_threshold, max_threshold, step_threshold):

            # ciclo sui folds con i che assume valori da 0 a len(X_train) - 1
            for i in range(len(X_Train)):

                # reset variabile
                if i == 0:
                    sum_f1_scores = 0

                # selezione delle feature in base alla soglia e ai valori del rank
                selected_features = [feature_name for feature_name, rank_value in rank if rank_value >= threshold]

                if len(selected_features) > 0:

                    # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                    X_train_subset = X_Train[i][selected_features]
                    X_test_subset = X_Test[i][selected_features]

                    # creazione di un albero decisionale con il criterio attuale
                    clf = DecisionTreeClassifier(criterion=criterion, random_state=42, min_samples_split=500)

                    # addestramento dell'albero decisionale sul training set
                    clf.fit(X_train_subset, Y_Train[i])

                    # previsioni dell'albero sul test set
                    y_pred = clf.predict(X_test_subset)

                    # calcolo dell'F1-Score dell'attuale fold
                    f1_scores = f1_score(Y_Test[i], y_pred)

                    # calcolo della somma degli F1-score per poter calcolare la media in seguito
                    sum_f1_scores = sum_f1_scores + f1_scores

                    # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                    if i == (len(X_Train) - 1):
                        avg_f1_score = (sum_f1_scores/(i+1))

                        # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                        if avg_f1_score > best_f1:
                            best_f1 = avg_f1_score
                            best_config = criterion
                            best_threshold = threshold
                            selected_features_lenght = len(selected_features)

    print("\nDeterminando la configurazione migliore dell'albero... completato!\n")

    return best_config, best_threshold, selected_features_lenght, best_f1


def determine_decision_tree_k_fold_configuration_PCA(XTrainPCA, YTrainPCA, XTestPCA, YTestPCA, explained_variance, minThreshold, maxThreshold, stepThreshold):
    sum_f1_scores = 0
    best_f1 = 0
    best_config = None
    best_threshold = 0
    selected_features_lenght = 0

    print("\n\nDeterminando la configurazione migliore dell'albero con la PCA...")

    for criterion in ['gini', 'entropy']:

        for threshold in np.arange(minThreshold, maxThreshold, stepThreshold):

            # ciclo sui folds con i che assume valori da 0 a len(XTrainPCA) - 1
            for i in range(len(XTrainPCA)):

                # reset variabile
                if i == 0:
                    sum_f1_scores = 0

                # calcolo del numero di principal component che superano la soglia attuale
                selected_features = number_of_top_pc_select(explained_variance, threshold)

                # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                X_train_subset = XTrainPCA[i].iloc[:, :selected_features]
                X_test_subset = XTestPCA[i].iloc[:, :selected_features]

                # creazione di un albero decisionale con il criterio attuale
                clf = DecisionTreeClassifier(criterion=criterion, random_state=42, min_samples_split=500)

                # addestramento dell'albero decisionale sul training set
                clf.fit(X_train_subset, YTrainPCA[i])

                # previsioni dell'albero sul test set
                y_pred = clf.predict(X_test_subset)

                # calcolo dell'F1-Score dell'attuale fold
                f1_scores = f1_score(YTestPCA[i], y_pred)

                # calcolo della somma degli F1-score per poter calcolare la media in seguito
                sum_f1_scores = sum_f1_scores + f1_scores

                # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                if i == (len(XTrainPCA) - 1):
                    avg_f1_score = (sum_f1_scores/(i+1))

                    # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                    if avg_f1_score > best_f1:
                        best_f1 = avg_f1_score
                        best_config = criterion
                        best_threshold = threshold
                        selected_features_lenght = selected_features

    print("\nDeterminando la configurazione migliore dell'albero con la PCA... completato!\n")

    return best_config, best_threshold, selected_features_lenght, best_f1


def determine_RF_k_fold_configuration(X_train, y_train, X_test, y_test, rank, min_threshold, max_threshold, step_threshold):
    print("\nDeterminando la configurazione migliore della Random Forest...")

    # conversione della lista di Dataframe y in array
    y_train_array = np.array([df.values.flatten() for df in y_train])
    y_test_array = np.array([df.values.flatten() for df in y_test])

    # definizioni dei parametri da testare
    criteria = ['gini', 'entropy']
    randomizations = ['sqrt', 'log2']
    bootstrap_sizes = [0.7, 0.8, 0.9]
    num_trees = [10, 20, 30]

    sum_f1_scores = 0
    best_config = 0
    best_rand = 0
    best_bootstrap = 0
    best_n_trees = 0
    best_f = 0
    best_n = 0
    best_th = 0

    # iterazioni su tutte le combinazioni dei parametri
    for criterion in criteria:
        for randomization in randomizations:
            for bootstrap in bootstrap_sizes:
                for n_trees in num_trees:
                    for threshold in np.arange(min_threshold, max_threshold, step_threshold):

                        # ciclo sui folds con i che assume valori da 0 a len(XTrain) - 1
                        for i in range(len(X_train)):

                            # reset variabile
                            if i == 0:
                                sum_f1_scores = 0

                            # selezione delle feature in base alla soglia e ai valori del rank
                            selected_features = [feature_name for feature_name, rank_value in rank if rank_value >= threshold]

                            if len(selected_features) > 0:

                                # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                                X_train_subset = X_train[i][selected_features]
                                X_test_subset = X_test[i][selected_features]

                                # creazione di una Random Forest con gli attuali parametri
                                rf_classifier = RandomForestClassifier(criterion=criterion,
                                                                       max_features=randomization,
                                                                       bootstrap=True,
                                                                       max_samples=bootstrap,
                                                                       n_estimators=n_trees,
                                                                       random_state=42)

                                # addestramento della Random Forest sul training set
                                rf_classifier.fit(X_train_subset, y_train_array[i])

                                # previsioni della Random Forest sul test set
                                y_pred = rf_classifier.predict(X_test_subset)

                                # calcolo dell'F1-Score dell'attuale fold
                                f1_scores = f1_score(y_test_array[i], y_pred)

                                # calcolo della somma degli F1-score per poter calcolare la media in seguito
                                sum_f1_scores = sum_f1_scores + f1_scores

                                # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                                if i == (len(X_train) - 1):
                                    avg_f1_score = (sum_f1_scores / (i + 1))

                                    # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                                    if avg_f1_score > best_f:
                                        best_config = criterion
                                        best_rand = randomization
                                        best_bootstrap = bootstrap
                                        best_n_trees = n_trees
                                        best_f = avg_f1_score
                                        best_n = len(selected_features)
                                        best_th = threshold

    print("\nDeterminando la configurazione migliore della Random Forest... completato!\n")

    return best_config, best_rand, best_bootstrap, best_n_trees, best_f, best_n, best_th


def determine_RF_k_fold_configuration_PCA(X_train, y_train, X_test, y_test, explained_variance, min_threshold, max_threshold, step_threshold):
    print("\nDeterminando la configurazione migliore della Random Forest con la PCA...")

    # conversione della lista di Dataframe y in array
    y_train_array = np.array([df.values.flatten() for df in y_train])
    y_test_array = np.array([df.values.flatten() for df in y_test])

    # definizioni dei parametri da testare
    criteria = ['gini', 'entropy']
    randomizations = ['sqrt', 'log2']
    bootstrap_sizes = [0.7, 0.8, 0.9]
    num_trees = [10, 20, 30]

    sum_f1_scores = 0
    best_config = 0
    best_rand = 0
    best_bootstrap = 0
    best_n_trees = 0
    best_f = 0
    best_n = 0
    best_th = 0

    # iterazioni su tutte le combinazioni dei parametri
    for criterion in criteria:
        for randomization in randomizations:
            for bootstrap in bootstrap_sizes:
                for n_trees in num_trees:
                    for threshold in np.arange(min_threshold, max_threshold, step_threshold):

                        # ciclo sui folds con i che assume valori da 0 a len(XTrain) - 1
                        for i in range(len(X_train)):

                            # reset variabile
                            if i == 0:
                                sum_f1_scores = 0

                            # calcolo del numero di principal component che superano la soglia attuale
                            selected_features = number_of_top_pc_select(explained_variance, threshold)

                            # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                            X_train_subset = X_train[i].iloc[:, :selected_features]
                            X_test_subset = X_test[i].iloc[:, :selected_features]

                            # creazione di una Random Forest con gli attuali parametri
                            rf_classifier = RandomForestClassifier(criterion=criterion,
                                                                   max_features=randomization,
                                                                   bootstrap=True,
                                                                   max_samples=bootstrap,
                                                                   n_estimators=n_trees,
                                                                   random_state=42)

                            # addestramento della Random Forest sul training set
                            rf_classifier.fit(X_train_subset, y_train_array[i])

                            # previsioni della Random Forest sul test set
                            y_pred = rf_classifier.predict(X_test_subset)

                            # calcolo dell'F1-Score dell'attuale fold
                            f1_scores = f1_score(y_test_array[i], y_pred)

                            # calcolo della somma degli F1-score per poter calcolare la media in seguito
                            sum_f1_scores = sum_f1_scores + f1_scores

                            # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                            if i == (len(X_train) - 1):
                                avg_f1_score = (sum_f1_scores / (i + 1))

                                # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                                if avg_f1_score > best_f:
                                    best_config = criterion
                                    best_rand = randomization
                                    best_bootstrap = bootstrap
                                    best_n_trees = n_trees
                                    best_f = avg_f1_score
                                    best_n = selected_features
                                    best_th = threshold

    print("\nDeterminando la configurazione migliore della Random Forest con la PCA... completato!\n")

    return best_config, best_rand, best_bootstrap, best_n_trees, best_f, best_n, best_th


def determine_KNN_k_fold_configuration(X_train, y_train, X_test, y_test, rank, min_threshold, max_threshold, step_threshold):
    print("\nDeterminando la configurazione migliore del KNN...")

    # definizione dei valori del parametro 'k' da testare
    k_values = [1, 3]

    best_k = None
    best_f1 = 0.0
    sum_f1_scores = 0
    selected_features_lenght = 0
    best_TH = 0

    # conversione della lista di Dataframe y in array
    y_train_array = np.array([df.values.flatten() for df in y_train])
    y_test_array = np.array([df.values.flatten() for df in y_test])

    # iterazioni su tutte le combinazioni dei parametri
    for k in k_values:
        for threshold in np.arange(min_threshold, max_threshold, step_threshold):

            # ciclo sui folds con i che assume valori da 0 a len(XTrain) - 1
            for i in range(len(X_train)):

                # reset variabile
                if i == 0:
                    sum_f1_scores = 0

                # selezione delle feature in base alla soglia e ai valori del rank
                selected_features = [feature_name for feature_name, rank_value in rank if rank_value >= threshold]

                if len(selected_features) > 0:

                    # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                    X_train_subset = X_train[i][selected_features]
                    X_test_subset = X_test[i][selected_features]

                    # creazione del KNN con l'attuale valore del parametro k
                    knn_classifier = KNeighborsClassifier(n_neighbors=k)

                    # addestramento del KNN sul training set
                    knn_classifier.fit(X_train_subset, y_train_array[i])

                    # previsioni del KNN sul test set
                    y_pred = knn_classifier.predict(X_test_subset)

                    # calcolo dell'F1-Score dell'attuale fold
                    f1_scores = f1_score(y_test_array[i], y_pred)

                    # calcolo della somma degli F1-score per poter calcolare la media in seguito
                    sum_f1_scores = sum_f1_scores + f1_scores

                    # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                    if i == (len(X_train) - 1):
                        avg_f1_score = (sum_f1_scores / (i + 1))

                        # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                        if avg_f1_score > best_f1:
                            best_k = k
                            best_f1 = avg_f1_score
                            best_TH = threshold
                            selected_features_lenght = len(selected_features)

    print("\nDeterminando la configurazione migliore del KNN... completato!\n")

    return best_k, best_f1, selected_features_lenght, best_TH


def determine_KNN_k_fold_configuration_PCA(X_train, y_train, X_test, y_test, explained_variance, min_threshold, max_threshold, step_threshold):
    print("\nDeterminando la configurazione migliore del KNN...")

    # definizione dei valori del parametro 'k' da testare
    k_values = [1, 3]

    best_k = None
    best_f1 = 0.0
    sum_f1_scores = 0
    selected_features_lenght = 0
    best_TH = 0

    # conversione della lista di Dataframe y in array
    y_train_array = np.array([df.values.flatten() for df in y_train])
    y_test_array = np.array([df.values.flatten() for df in y_test])

    # iterazioni su tutte le combinazioni dei parametri
    for k in k_values:
        for threshold in np.arange(min_threshold, max_threshold, step_threshold):

            # ciclo sui folds con i che assume valori da 0 a len(XTrain) - 1
            for i in range(len(X_train)):

                # reset variabile
                if i == 0:
                    sum_f1_scores = 0

                # calcolo del numero di principal component che superano la soglia attuale
                selected_features = number_of_top_pc_select(explained_variance, threshold)

                # ottenimento del sottoinsieme delle feature selezionate dal training set e dal test set
                X_train_subset = X_train[i].iloc[:, :selected_features]
                X_test_subset = X_test[i].iloc[:, :selected_features]

                # creazione del KNN con l'attuale valore del parametro k
                knn_classifier = KNeighborsClassifier(n_neighbors=k)

                # addestramento del KNN sul training set
                knn_classifier.fit(X_train_subset, y_train_array[i])

                # previsioni del KNN sul test set
                y_pred = knn_classifier.predict(X_test_subset)

                # calcolo dell'F1-Score dell'attuale fold
                f1_scores = f1_score(y_test_array[i], y_pred)

                # calcolo della somma degli F1-score per poter calcolare la media in seguito
                sum_f1_scores = sum_f1_scores + f1_scores

                # calcolo della media degli F1_score dei folds all'ultima iterata "i" dei folds
                if i == (len(X_train) - 1):
                    avg_f1_score = (sum_f1_scores / (i + 1))

                    # aggiornamento della miglior configurazione se l'attuale media degli F1-Score è più alta
                    if avg_f1_score > best_f1:
                        best_k = k
                        best_f1 = avg_f1_score
                        best_TH = threshold
                        selected_features_lenght = selected_features

    print("\nDeterminando la configurazione migliore del KNN... completato!\n")

    return best_k, best_f1, selected_features_lenght, best_TH

